{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c290dd25",
   "metadata": {},
   "source": [
    "### Build a Retrieval Augmented Generation (RAG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aea4f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "# Suppress all warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b79fda",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "!pip install groq  -q\n",
    "!pip install qdrant-client -q\n",
    "!pip install sentence-transformers -q\n",
    "!pip install langchain -q\n",
    "!pip install pypdf  -q "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "e31337ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from groq import Groq\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.models import PointStruct\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f76c0a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv('.env')  \n",
    "GROQ_API_KEY = os.getenv(\"GROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a14adc11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize embedding model using Sentence Transformers\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "vector_size = embedding_model.embed_query(\"test\").__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "7988e429",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Qdrant Client (using in-memory or adjust to your needs)\n",
    "qdrant = QdrantClient(\":memory:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "b78bdd69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a Qdrant collection to hold document vectors\n",
    "qdrant.recreate_collection(\n",
    "    collection_name=\"documents\",\n",
    "    vectors_config={\"size\": vector_size, \"distance\": \"Cosine\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "3f85ac38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load PDF document\n",
    "loader = PyPDFLoader(\"../pdf/‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏¢‡∏≤ 50 ‡∏ä‡∏ô‡∏¥‡∏î.pdf\")\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "e06b3428",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the documents into smaller chunks\n",
    "splitter = CharacterTextSplitter(chunk_size=500, chunk_overlap=200)\n",
    "document_chunks = splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "391d0630",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UpdateResult(operation_id=0, status=<UpdateStatus.COMPLETED: 'completed'>)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract text from document chunks\n",
    "texts = [doc.page_content for doc in document_chunks]\n",
    "\n",
    "# Convert texts into vectors\n",
    "vectors = embedding_model.embed_documents(texts)\n",
    "\n",
    "# Upsert data into Qdrant\n",
    "points = [PointStruct(id=i, vector=vectors[i], payload={\"text\": texts[i]}) for i in range(len(texts))]\n",
    "qdrant.upsert(collection_name=\"documents\", points=points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "520ddccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_documents(query):\n",
    "    # Convert query to vector\n",
    "    query_vector = embedding_model.embed_query(query)\n",
    "    \n",
    "    # Search Qdrant for similar documents\n",
    "    search_results = qdrant.search(\n",
    "        collection_name=\"documents\",\n",
    "        query_vector=query_vector,\n",
    "        limit=4  # Retrieve top 5 relevant documents\n",
    "    )\n",
    "    \n",
    "    # Check if results are found\n",
    "    if not search_results:\n",
    "        return []  # Return empty if no documents found\n",
    "    \n",
    "    # Extract text from results \n",
    "    return [hit.payload.get(\"text\", \"‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°\") for hit in search_results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "34d8cc36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_answer(query):\n",
    "    '''\n",
    "        \n",
    "    '''\n",
    "    # Retrieve relevant documents from Qdrant\n",
    "    retrieved_docs = search_documents(query)\n",
    "\n",
    "    # Check if any documents were retrieved\n",
    "    if not retrieved_docs:\n",
    "        return \"‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á\"  # \"No relevant information found\"\n",
    "\n",
    "    # Create the context for the language model\n",
    "    context = \"\\n\".join([str(doc) for doc in retrieved_docs if isinstance(doc, str)])\n",
    "\n",
    "    # Check if context has content\n",
    "    if not context.strip():\n",
    "        # \"No relevant information found\"\n",
    "        return \"‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á\"\n",
    "\n",
    "    prompt = f\"‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á:\\n{context}\\n\\n‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°: {query}\\n\\n‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö:\"\n",
    "\n",
    "    # Initialize Groq API client\n",
    "    groq_client = Groq(api_key=os.getenv(\"GROQ_API_KEY\"))\n",
    "\n",
    "    try:\n",
    "        # Requesting completion from Groq API\n",
    "        response = groq_client.chat.completions.create(\n",
    "            model=\"llama-3.1-8b-instant\", messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        return f\"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö: {str(e)}\"\n",
    "    # \"Error occurred in generating the answer\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "33d922fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‡∏°‡∏µ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏¢‡∏≤‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î 25 ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£\n"
     ]
    }
   ],
   "source": [
    "# üî• Test the question!\n",
    "query = \"‡∏°‡∏µ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏≠‡∏∞‡πÑ‡∏£‡∏ö‡πâ‡∏≤‡∏á\"  \n",
    "answer = generate_answer(query)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "3d92234b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‡∏¢‡∏≤‡∏ó‡∏µ‡πà‡∏Ñ‡∏∏‡∏ì‡∏ñ‡∏≤‡∏°‡∏ñ‡∏∂‡∏á‡∏Ñ‡∏∑‡∏≠ \"‡∏û‡∏≤‡∏£‡∏≤‡πÄ‡∏ã‡∏ï‡∏≤‡∏°‡∏≠‡∏•\" (Paracetamol) ‡πÅ‡∏•‡∏∞‡∏°‡∏µ‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏î‡∏±‡∏á‡∏ô‡∏µ‡πâ\n",
      "\n",
      "- ‡∏™‡πà‡∏ß‡∏ô‡∏ú‡∏™‡∏°: ‡∏û‡∏≤‡∏£‡∏≤‡πÄ‡∏ã‡∏ï‡∏≤‡∏°‡∏≠‡∏•\n",
      "- ‡∏™‡∏π‡∏ï‡∏£‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏™‡∏π‡∏á‡∏™‡∏†‡∏≤‡∏ß‡∏∞: ‡∏û‡∏≤‡∏£‡∏≤‡πÄ‡∏ã‡∏ï‡∏≤‡∏°‡∏≠‡∏•-‡∏™‡∏±‡∏°‡∏û‡∏±‡∏ô‡∏ò‡∏∏‡πå: ‡∏ö‡∏£‡∏£‡πÄ‡∏ó‡∏≤‡∏≠‡∏≤‡∏Å‡∏≤‡∏£‡∏õ‡∏ß‡∏î‡πÅ‡∏•‡∏∞‡∏≠‡∏≤‡∏Å‡∏≤‡∏£‡∏´‡∏ô‡∏≤‡∏ß\n",
      "- ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ:\n",
      " + ‡∏ú‡∏π‡πâ‡πÉ‡∏´‡∏ç‡πà: ‡∏ú‡∏π‡πâ‡πÉ‡∏´‡∏ç‡πà‡πÉ‡∏´‡πâ‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏ó‡∏µ‡πà 0.5-1 ‡∏Å‡∏£‡∏±‡∏° (5-10 ‡∏°.‡∏•‡∏•.) ‡∏ó‡∏∏‡∏Å‡πÜ 4-6 ‡∏ä‡∏±‡πà‡∏ß‡πÇ‡∏°‡∏á‡∏°‡∏≤‡∏Å‡∏™‡∏∏‡∏î 4-6 ‡∏ä‡∏±‡πà‡∏ß‡πÇ‡∏°‡∏á‡∏ï‡πà‡∏≠‡∏ß‡∏±‡∏ô\n",
      " + ‡πÅ‡∏ï‡πà‡∏ú‡∏π‡πâ‡∏ö‡∏£‡∏≠‡∏Å‡∏î‡∏ï‡∏≤‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡πÅ‡∏•‡∏∞‡πÑ‡∏°‡πà‡πÄ‡∏Å‡∏¥‡∏ô 4 ‡∏Å‡∏£‡∏±‡∏°‡∏ï‡πà‡∏≠‡∏ß‡∏±‡∏ô\n",
      " + ‡∏ô‡∏≠‡∏Å‡∏à‡∏≤‡∏Å‡∏ô‡∏µ‡πâ‡∏¢‡∏±‡∏á‡∏°‡∏µ‡∏Ç‡∏≠‡∏¢‡∏Å‡πÄ‡∏ß‡πâ‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏î‡πá‡∏Å ‡πÄ‡∏û‡∏£‡∏≤‡∏∞‡πÑ‡∏°‡πà‡πÄ‡∏Å‡∏¥‡∏î‡∏ú‡∏•‡∏°‡∏≤‡∏Å‡∏ô‡∏±‡∏Å ‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡πÅ‡∏ï‡πà‡∏ß‡∏±‡∏ô‡πÅ‡∏£‡∏Å‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÉ‡∏ä‡πâ‡πÑ‡∏î‡πâ‡πÅ‡∏ï‡πà‡∏•‡∏î‡∏ô‡πâ‡∏≠‡∏¢‡∏•‡∏á‡πÄ‡∏´‡∏•‡∏∑‡∏≠ 1 ‡∏ä‡∏±‡πà‡∏ß‡πÇ‡∏°‡∏á\n",
      "- ‡∏Ñ‡πà‡∏≤‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥: ‡∏ö‡∏£‡∏£‡πÄ‡∏ó‡∏≤‡∏≠‡∏≤‡∏Å‡∏≤‡∏£‡∏õ‡∏ß‡∏î‡πÅ‡∏•‡∏∞‡∏≠‡∏≤‡∏Å‡∏≤‡∏£‡∏´‡∏ô‡∏≤‡∏ß\n",
      "- ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡πÉ‡∏ä‡πâ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏õ‡∏±‡∏ç‡∏´‡∏≤:\n",
      " + ‡∏≠‡∏≤‡∏à‡πÉ‡∏ä‡πâ‡πÄ‡∏õ‡πá‡∏ô‡∏†‡∏≤‡∏ä‡∏ô‡∏∞‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏à‡πá‡∏ö‡∏õ‡∏ß‡∏î\n",
      " * (‡∏î‡∏π‡πÑ‡∏î‡πâ‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏° \"‡∏´‡πâ‡∏≤‡∏°‡πÉ‡∏ä‡πâ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏ó‡∏±‡∏ô‡∏ó‡∏µ‡∏ï‡πà‡∏≠‡πÄ‡∏ß‡∏•‡∏≤‡∏à‡∏≤‡∏Å‡∏Å‡∏≤‡∏£‡πÄ‡∏™‡∏µ‡∏¢\"\n",
      " - ‡∏Ñ‡∏≥‡πÄ‡∏ï‡∏∑‡∏≠‡∏ô: ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÉ‡∏ä‡πâ‡∏¢‡∏≤‡∏ß‡∏ô‡∏≤‡∏ô‡∏´‡∏£‡∏∑‡∏≠‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏°‡∏≤‡∏Å ‡πÑ‡∏î‡πâ‡πÄ‡∏à‡πá‡∏ö‡∏°‡∏≤‡∏Å‡πÅ‡∏•‡∏∞‡πÄ‡∏™‡∏µ‡∏¢‡∏£‡∏∞‡∏ö‡∏ö‡∏´‡∏£‡∏∑‡∏≠‡∏õ‡∏¥‡∏ï‡∏¥\n"
     ]
    }
   ],
   "source": [
    "# üî• Test the question!\n",
    "query = \"‡∏Ç‡∏≠‡∏£‡∏≤‡∏¢‡∏≠‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏Ç‡∏≠‡∏á‡∏¢‡∏≤  ‡∏û‡∏≤‡∏£‡∏≤‡πÄ‡∏ã‡∏ï‡∏≤‡∏°‡∏≠‡∏•(Paracetamol)\"  \n",
    "answer = generate_answer(query)\n",
    "print(answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
