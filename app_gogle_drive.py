import os
import gdown
import streamlit as st
from dotenv import load_dotenv
from groq import Groq
from qdrant_client import QdrantClient
from qdrant_client.models import PointStruct
from langchain.embeddings import HuggingFaceEmbeddings
from langchain.text_splitter import CharacterTextSplitter
from langchain.schema import Document
from docling.document_converter import DocumentConverter

# Load environment variables
load_dotenv(".env")
GROQ_API_KEY = os.getenv("GROQ_API_KEY")
PDF_ID = os.getenv("PDF_ID")

# Define PDF path
pdf_path = "./dataset/downloaded_document.pdf"


# Download PDF from Google Drive
def download_pdf_from_drive():
    if not PDF_ID:
        st.error("‚ùå PDF_ID not found in .env file.")
        return False
    try:
        os.makedirs("./dataset", exist_ok=True)
        gdown.download(
            f"https://drive.google.com/uc?id={PDF_ID}", pdf_path, quiet=False
        )
        return True
    except Exception as e:
        st.error(f"‚ùå Error downloading PDF: {str(e)}")
        return False


# Initialize services
def initialize_services():
    embedding_model = HuggingFaceEmbeddings(
        model_name="sentence-transformers/all-MiniLM-L6-v2"
    )
    vector_size = len(embedding_model.embed_query("test"))
    qdrant = QdrantClient(":memory:")
    qdrant.recreate_collection(
        collection_name="documents",
        vectors_config={"size": vector_size, "distance": "Cosine"},
    )
    return qdrant, embedding_model


# Add documents to Qdrant
def add_documents_to_qdrant(qdrant, embedding_model):
    converter = DocumentConverter()
    result = converter.convert(pdf_path)
    markdown_text = result.document.export_to_markdown()
    doc = Document(page_content=markdown_text)
    splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
    document_chunks = splitter.split_documents([doc])

    texts = [d.page_content for d in document_chunks]
    vectors = embedding_model.embed_documents(texts)
    points = [
        PointStruct(id=i, vector=vectors[i], payload={"text": texts[i]})
        for i in range(len(texts))
    ]
    qdrant.upsert(collection_name="documents", points=points)


# Search function
def search_documents(query, qdrant, embedding_model):
    query_vector = embedding_model.embed_query(query)
    results = qdrant.search(
        collection_name="documents",
        query_vector=query_vector,
        limit=4,
    )
    return [hit.payload.get("text", "‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°") for hit in results]


# Generate answer with Groq
def generate_answer(query, qdrant, embedding_model):
    docs = search_documents(query, qdrant, embedding_model)
    if not docs:
        return "‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á"

    context = "\n".join([str(doc) for doc in docs if isinstance(doc, str)])
    if not context.strip():
        return "‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á"

    prompt = f"‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á:\n{context}\n\n‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°: {query}\n\n‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö:"
    groq_client = Groq(api_key=GROQ_API_KEY)
    try:
        response = groq_client.chat.completions.create(
            model="llama-3.1-8b-instant", messages=[{"role": "user", "content": prompt}]
        )
        return response.choices[0].message.content
    except Exception as e:
        return f"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö: {str(e)}"


# Streamlit app
def main():
    global qdrant, embedding_model
    st.set_page_config(page_title="RAG Chatbot", page_icon="ü§ñ", layout="wide")
    st.title("ü§ñ AI Innovator LLM & RAG")
    st.subheader("Chatbot ‡∏ä‡πà‡∏ß‡∏¢‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£")
    st.markdown(
        "<center>‡∏ú‡∏π‡πâ‡∏û‡∏±‡∏í‡∏ô‡∏≤‡πÇ‡∏î‡∏¢: Jeerasak ss4 (Game)</center>", unsafe_allow_html=True
    )

    if download_pdf_from_drive():
        qdrant, embedding_model = initialize_services()
        add_documents_to_qdrant(qdrant, embedding_model)
        st.success("‚úÖ ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡πÅ‡∏•‡πâ‡∏ß!")

    query = st.text_input("‡∏Ñ‡∏∏‡∏ì:", placeholder="‡∏û‡∏¥‡∏°‡∏û‡πå‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì‡∏ó‡∏µ‡πà‡∏ô‡∏µ‡πà...")

    if "messages" not in st.session_state:
        st.session_state["messages"] = [
            {"role": "assistant", "content": "‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ ‡∏°‡∏µ‡∏≠‡∏∞‡πÑ‡∏£‡πÉ‡∏´‡πâ‡∏ä‡πà‡∏ß‡∏¢‡πÑ‡∏´‡∏° :)"}
        ]

    if st.button("‡∏™‡πà‡∏á"):
        if query:
            answer = generate_answer(query, qdrant, embedding_model)
            st.session_state["messages"].append({"role": "user", "content": query})
            st.session_state["messages"].append(
                {"role": "assistant", "content": answer}
            )
        else:
            st.warning("‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏û‡∏¥‡∏°‡∏û‡πå‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏Å‡πà‡∏≠‡∏ô‡∏™‡πà‡∏á")

    for msg in st.session_state["messages"]:
        role = "Bot" if msg["role"] == "assistant" else "‡∏Ñ‡∏∏‡∏ì"
        st.write(f"**{role}:** {msg['content']}")


if __name__ == "__main__":
    main()
